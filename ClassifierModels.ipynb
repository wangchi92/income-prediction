{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# visualiation\n",
    "#import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# model training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# feature engineering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# model evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# classifiers\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
    "from sklearn.linear_model import LogisticRegression # logistic regression\n",
    "from sklearn.tree import DecisionTreeClassifier # decision tree\n",
    "from sklearn.ensemble import RandomForestClassifier # random forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_file = './data/train.csv'\n",
    "train_data = pd.read_csv(train_file)\n",
    "train_data = pd.DataFrame(data=train_data)\n",
    "\n",
    "test_file = './data/test.csv'\n",
    "test_data = pd.read_csv(test_file)\n",
    "test_data = pd.DataFrame(data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>workclass_ Never-worked</th>\n",
       "      <th>workclass_ Private</th>\n",
       "      <th>...</th>\n",
       "      <th>occupation_ Tech-support</th>\n",
       "      <th>occupation_ Transport-moving</th>\n",
       "      <th>relationship_ Husband</th>\n",
       "      <th>relationship_ Not-in-family</th>\n",
       "      <th>relationship_ Other-relative</th>\n",
       "      <th>relationship_ Own-child</th>\n",
       "      <th>relationship_ Unmarried</th>\n",
       "      <th>relationship_ Wife</th>\n",
       "      <th>sex_ Female</th>\n",
       "      <th>sex_ Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4441</td>\n",
       "      <td>-0.627855</td>\n",
       "      <td>-0.596586</td>\n",
       "      <td>-0.425925</td>\n",
       "      <td>-0.145954</td>\n",
       "      <td>-0.216863</td>\n",
       "      <td>0.362925</td>\n",
       "      <td>-0.176156</td>\n",
       "      <td>-0.265404</td>\n",
       "      <td>-0.016933</td>\n",
       "      <td>0.669478</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175909</td>\n",
       "      <td>-0.222605</td>\n",
       "      <td>1.214916</td>\n",
       "      <td>-0.584774</td>\n",
       "      <td>-0.182122</td>\n",
       "      <td>-0.430146</td>\n",
       "      <td>-0.340634</td>\n",
       "      <td>-0.227227</td>\n",
       "      <td>-0.703375</td>\n",
       "      <td>0.703375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16596</td>\n",
       "      <td>-1.139672</td>\n",
       "      <td>0.804556</td>\n",
       "      <td>-2.368098</td>\n",
       "      <td>-0.145954</td>\n",
       "      <td>-0.216863</td>\n",
       "      <td>-1.658539</td>\n",
       "      <td>-0.176156</td>\n",
       "      <td>-0.265404</td>\n",
       "      <td>-0.016933</td>\n",
       "      <td>0.669478</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175909</td>\n",
       "      <td>-0.222605</td>\n",
       "      <td>1.214916</td>\n",
       "      <td>-0.584774</td>\n",
       "      <td>-0.182122</td>\n",
       "      <td>-0.430146</td>\n",
       "      <td>-0.340634</td>\n",
       "      <td>-0.227227</td>\n",
       "      <td>-0.703375</td>\n",
       "      <td>0.703375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6876</td>\n",
       "      <td>1.346294</td>\n",
       "      <td>-0.521784</td>\n",
       "      <td>-0.425925</td>\n",
       "      <td>-0.145954</td>\n",
       "      <td>-0.216863</td>\n",
       "      <td>-0.041368</td>\n",
       "      <td>-0.176156</td>\n",
       "      <td>-0.265404</td>\n",
       "      <td>-0.016933</td>\n",
       "      <td>0.669478</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175909</td>\n",
       "      <td>-0.222605</td>\n",
       "      <td>1.214916</td>\n",
       "      <td>-0.584774</td>\n",
       "      <td>-0.182122</td>\n",
       "      <td>-0.430146</td>\n",
       "      <td>-0.340634</td>\n",
       "      <td>-0.227227</td>\n",
       "      <td>-0.703375</td>\n",
       "      <td>0.703375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15486</td>\n",
       "      <td>1.273178</td>\n",
       "      <td>-1.099788</td>\n",
       "      <td>-2.368098</td>\n",
       "      <td>-0.145954</td>\n",
       "      <td>-0.216863</td>\n",
       "      <td>-0.041368</td>\n",
       "      <td>-0.176156</td>\n",
       "      <td>-0.265404</td>\n",
       "      <td>-0.016933</td>\n",
       "      <td>0.669478</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175909</td>\n",
       "      <td>-0.222605</td>\n",
       "      <td>1.214916</td>\n",
       "      <td>-0.584774</td>\n",
       "      <td>-0.182122</td>\n",
       "      <td>-0.430146</td>\n",
       "      <td>-0.340634</td>\n",
       "      <td>-0.227227</td>\n",
       "      <td>-0.703375</td>\n",
       "      <td>0.703375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15141</td>\n",
       "      <td>-1.212788</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>-0.037490</td>\n",
       "      <td>-0.145954</td>\n",
       "      <td>-0.216863</td>\n",
       "      <td>-0.041368</td>\n",
       "      <td>-0.176156</td>\n",
       "      <td>-0.265404</td>\n",
       "      <td>-0.016933</td>\n",
       "      <td>0.669478</td>\n",
       "      <td>...</td>\n",
       "      <td>5.684761</td>\n",
       "      <td>-0.222605</td>\n",
       "      <td>-0.823102</td>\n",
       "      <td>-0.584774</td>\n",
       "      <td>-0.182122</td>\n",
       "      <td>2.324794</td>\n",
       "      <td>-0.340634</td>\n",
       "      <td>-0.227227</td>\n",
       "      <td>-0.703375</td>\n",
       "      <td>0.703375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "4441  -0.627855 -0.596586      -0.425925     -0.145954     -0.216863   \n",
       "16596 -1.139672  0.804556      -2.368098     -0.145954     -0.216863   \n",
       "6876   1.346294 -0.521784      -0.425925     -0.145954     -0.216863   \n",
       "15486  1.273178 -1.099788      -2.368098     -0.145954     -0.216863   \n",
       "15141 -1.212788  0.001238      -0.037490     -0.145954     -0.216863   \n",
       "\n",
       "       hours-per-week  workclass_ Federal-gov  workclass_ Local-gov  \\\n",
       "4441         0.362925               -0.176156             -0.265404   \n",
       "16596       -1.658539               -0.176156             -0.265404   \n",
       "6876        -0.041368               -0.176156             -0.265404   \n",
       "15486       -0.041368               -0.176156             -0.265404   \n",
       "15141       -0.041368               -0.176156             -0.265404   \n",
       "\n",
       "       workclass_ Never-worked  workclass_ Private  ...  \\\n",
       "4441                 -0.016933            0.669478  ...   \n",
       "16596                -0.016933            0.669478  ...   \n",
       "6876                 -0.016933            0.669478  ...   \n",
       "15486                -0.016933            0.669478  ...   \n",
       "15141                -0.016933            0.669478  ...   \n",
       "\n",
       "       occupation_ Tech-support  occupation_ Transport-moving  \\\n",
       "4441                  -0.175909                     -0.222605   \n",
       "16596                 -0.175909                     -0.222605   \n",
       "6876                  -0.175909                     -0.222605   \n",
       "15486                 -0.175909                     -0.222605   \n",
       "15141                  5.684761                     -0.222605   \n",
       "\n",
       "       relationship_ Husband  relationship_ Not-in-family  \\\n",
       "4441                1.214916                    -0.584774   \n",
       "16596               1.214916                    -0.584774   \n",
       "6876                1.214916                    -0.584774   \n",
       "15486               1.214916                    -0.584774   \n",
       "15141              -0.823102                    -0.584774   \n",
       "\n",
       "       relationship_ Other-relative  relationship_ Own-child  \\\n",
       "4441                      -0.182122                -0.430146   \n",
       "16596                     -0.182122                -0.430146   \n",
       "6876                      -0.182122                -0.430146   \n",
       "15486                     -0.182122                -0.430146   \n",
       "15141                     -0.182122                 2.324794   \n",
       "\n",
       "       relationship_ Unmarried  relationship_ Wife  sex_ Female  sex_ Male  \n",
       "4441                 -0.340634           -0.227227    -0.703375   0.703375  \n",
       "16596                -0.340634           -0.227227    -0.703375   0.703375  \n",
       "6876                 -0.340634           -0.227227    -0.703375   0.703375  \n",
       "15486                -0.340634           -0.227227    -0.703375   0.703375  \n",
       "15141                -0.340634           -0.227227    -0.703375   0.703375  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categorical\n",
    "def preprocess(data):\n",
    "    preprocessed_data = data.copy()\n",
    "    \n",
    "    # drop - too many categories and not very relevant intuitively\n",
    "    preprocessed_data = preprocessed_data.drop(['native-country'], axis=1)\n",
    "    # drop - duplicate of education-num\n",
    "    preprocessed_data = preprocessed_data.drop(['education'], axis=1)\n",
    "    preprocessed_data = pd.get_dummies(preprocessed_data)\n",
    "    preprocessed_data = preprocessed_data.drop(['occupation_ ?'], axis=1)\n",
    "    preprocessed_data = preprocessed_data.drop(['workclass_ ?'], axis=1)\n",
    "    \n",
    "    return preprocessed_data\n",
    "\n",
    "preprocessed_train_data = preprocess(train_data)\n",
    "preprocessed_test_data = preprocess(test_data)\n",
    "\n",
    "x_train = preprocessed_train_data.drop('exceeds50K', axis=1)\n",
    "y_train = preprocessed_train_data['exceeds50K']\n",
    "#normalization\n",
    "x_train_normalized = StandardScaler().fit_transform(x_train)\n",
    "x_train = pd.DataFrame(x_train_normalized, columns=x_train.columns)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.25, random_state=42, shuffle=True)\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try all classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Z:\\Users\\wayne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "Z:\\Users\\wayne\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "Z:\\Users\\wayne\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "Z:\\Users\\wayne\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "          f1    acc\n",
      "Model              \n",
      "KNN    82.40  82.82\n",
      "LR     85.08  85.59\n",
      "DT     80.87  80.71\n",
      "RF     84.31  84.93\n",
      "GBM    86.64  87.31\n",
      "LDA    83.45  84.08\n",
      "GNB    62.18  59.70\n",
      "SVC    84.73  85.29\n"
     ]
    }
   ],
   "source": [
    "# RUN MODELS\n",
    "\n",
    "classifiers = [KNeighborsClassifier, LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, GradientBoostingClassifier, LinearDiscriminantAnalysis, GaussianNB, SVC]\n",
    "model_names = ['KNN', 'LR', 'DT', 'RF', 'GBM', 'LDA', 'GNB', 'SVC'] \n",
    "\n",
    "acc = []\n",
    "f1 = []\n",
    "for classifier in classifiers:\n",
    "    model = classifier().fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    f1.append(round(f1_score(y_test, y_pred, average='weighted') * 100, 2))\n",
    "    acc.append(round(accuracy_score(y_test, y_pred) * 100, 2))\n",
    "\n",
    "F1_record = pd.DataFrame({'Model': model_names, 'f1': f1, 'acc': acc})\n",
    "#F1_record['F1_mean'] = F1_record.mean(axis=1).round(2)\n",
    "F1_record.set_index('Model', inplace=True)\n",
    "#F1_record.loc['avg'] = F1_record.mean()\n",
    "\n",
    "print('\\n')\n",
    "print(F1_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Hyperparameters\n",
    "> GBM seems to be the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=2)]: Done  80 out of  80 | elapsed:  6.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6}\n",
      "0.7095822769615525\n"
     ]
    }
   ],
   "source": [
    "# TUNE HYPERPARAMETERS\n",
    "classifier = GradientBoostingClassifier()\n",
    "#learning_rate = np.arange(0.3, 2.1, 0.3)\n",
    "max_depth = list(range(3,11))\n",
    "param_grid = dict(max_depth=max_depth)\n",
    "grid = GridSearchCV(classifier, param_grid=param_grid, cv=10, scoring='f1', verbose=True, n_jobs=2)\n",
    "grid.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.73\n",
      "87.15\n"
     ]
    }
   ],
   "source": [
    "# TEST TUNED HYPERPARAMETERS\n",
    "classifier = GradientBoostingClassifier(learning_rate=0.1, n_estimators=700, max_depth=3)\n",
    "model = classifier.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_train)\n",
    "print(round(f1_score(y_train, y_pred, average='weighted') * 100, 2))\n",
    "y_pred = model.predict(x_test)\n",
    "print(round(f1_score(y_test, y_pred, average='weighted') * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "24422\n"
     ]
    }
   ],
   "source": [
    "# SAVE Y_PRED TO CSV FILE\n",
    "print(y_pred)\n",
    "y_pred_file_name = './predictions.csv'\n",
    "y_pred_file = open(y_pred_file_name, 'w')\n",
    "output = 'id,prediction\\n'\n",
    "index = 1\n",
    "for i in y_pred:\n",
    "    output += str(index)\n",
    "    output += ','\n",
    "    output += str(i)\n",
    "    output += '\\n'\n",
    "    index += 1\n",
    "y_pred_file.write(output)\n",
    "y_pred_file.close()\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
