{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# visualiation\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# model training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# model evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# classifiers\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
    "from sklearn.linear_model import LogisticRegression # logistic regression\n",
    "from sklearn.tree import DecisionTreeClassifier # decision tree\n",
    "from sklearn.ensemble import RandomForestClassifier # random forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_file = './data/train.csv'\n",
    "train_data = pd.read_csv(train_file)\n",
    "train_data = pd.DataFrame(data=train_data)\n",
    "\n",
    "test_file = './data/test.csv'\n",
    "test_data = pd.read_csv(test_file)\n",
    "test_data = pd.DataFrame(data=test_data)\n",
    "\n",
    "test_ground_truths_file = './data/test_ground_truths.csv'\n",
    "test_ground_truths = pd.read_csv(test_ground_truths_file)\n",
    "test_ground_truths = pd.DataFrame(data=test_ground_truths)\n",
    "\n",
    "test_data['exceeds50K'] = test_ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>exceeds50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>?</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>Private</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>?</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>Private</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>7298</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  education-num       marital-status       occupation  \\\n",
       "0   30         ?             10        Never-married                ?   \n",
       "1   60   Private             13             Divorced   Prof-specialty   \n",
       "2   52         ?             10   Married-civ-spouse                ?   \n",
       "3   37   Private             13   Married-civ-spouse            Sales   \n",
       "4   63   Private             10   Married-civ-spouse            Sales   \n",
       "\n",
       "     relationship      sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0       Own-child   Female             0             0              30   \n",
       "1   Not-in-family   Female             0             0              42   \n",
       "2         Husband     Male             0             0              12   \n",
       "3         Husband     Male             0             0              60   \n",
       "4         Husband     Male          7298             0              48   \n",
       "\n",
       "   exceeds50K  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           1  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove unwanted columns\n",
    "def chooseColumns(data):\n",
    "    data_copy = data.copy()\n",
    "    \n",
    "    # too many categories, drop for now\n",
    "    data_copy = data_copy.drop(['native-country', 'education', 'fnlwgt'], axis=1)\n",
    "    \n",
    "    return data_copy\n",
    "\n",
    "#preprocessed_data = pd.get_dummies(preprocessed_data)\n",
    "processed_train_data = chooseColumns(train_data)\n",
    "processed_test_data = chooseColumns(test_data)\n",
    "\n",
    "processed_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24421, 44) (24421,)\n",
      "(24421, 44) (24421,)\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['workclass', 'marital-status', 'occupation', 'relationship', 'sex']\n",
    "onehot_train_data = pd.get_dummies(processed_train_data, columns=categorical_columns)\n",
    "onehot_train_labels = processed_train_data['exceeds50K']\n",
    "onehot_test_data = pd.get_dummies(processed_test_data, columns=categorical_columns)\n",
    "onehot_test_labels = processed_train_data['exceeds50K']\n",
    "\n",
    "X_train = onehot_train_data.drop(['exceeds50K'], axis=1).to_numpy()\n",
    "y_train = onehot_train_labels.to_numpy()\n",
    "X_test = onehot_test_data.drop(['exceeds50K'], axis=1).to_numpy()\n",
    "y_test = onehot_test_labels.to_numpy()\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp model definition\n",
    "\n",
    "## Importing required libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "#s = tf.InteractiveSession()\n",
    "\n",
    "num_classes = y_train.shape[1]\n",
    "num_features = X_train.shape[1]\n",
    "num_output = y_train.shape[1]\n",
    "num_layers_0 = 1024\n",
    "num_layers_1 = 512\n",
    "starter_learning_rate = 0.001\n",
    "regularizer_rate = 0.1\n",
    "\n",
    "# Placeholders for the input data\n",
    "input_X = tf.placeholder('float32',shape =(None,num_features),name=\"input_X\")\n",
    "input_y = tf.placeholder('float32',shape = (None,num_classes),name='input_Y')\n",
    "## for dropout layer\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "## Weights initialized by random normal function with std_dev = 1/sqrt(number of input features)\n",
    "weights_0 = tf.Variable(tf.random_normal([num_features,num_layers_0], stddev=(1/tf.sqrt(float(num_features)))))\n",
    "bias_0 = tf.Variable(tf.random_normal([num_layers_0]))\n",
    "weights_1 = tf.Variable(tf.random_normal([num_layers_0,num_layers_1], stddev=(1/tf.sqrt(float(num_layers_0)))))\n",
    "bias_1 = tf.Variable(tf.random_normal([num_layers_1]))\n",
    "weights_2 = tf.Variable(tf.random_normal([num_layers_1,num_output], stddev=(1/tf.sqrt(float(num_layers_1)))))\n",
    "bias_2 = tf.Variable(tf.random_normal([num_output]))\n",
    "\n",
    "## Initializing weigths and biases\n",
    "hidden_output_0 = tf.nn.relu(tf.matmul(input_X,weights_0)+bias_0)\n",
    "hidden_output_0_0 = tf.nn.dropout(hidden_output_0, rate=1-keep_prob)\n",
    "hidden_output_1 = tf.nn.relu(tf.matmul(hidden_output_0_0,weights_1)+bias_1)\n",
    "hidden_output_1_1 = tf.nn.dropout(hidden_output_1, rate=1-keep_prob)\n",
    "predicted_y = tf.sigmoid(tf.matmul(hidden_output_1_1,weights_2) + bias_2)\n",
    "\n",
    "## Defining the loss function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=predicted_y,labels=input_y)) \\\n",
    "        + regularizer_rate*(tf.reduce_sum(tf.square(bias_0)) + tf.reduce_sum(tf.square(bias_1)))\n",
    "\n",
    "## Variable learning rate\n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, 0, 5, 0.85, staircase=True)\n",
    "## Adam optimzer for finding the right weight\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss,var_list=[weights_0,weights_1,weights_2,\n",
    "                                                                         bias_0,bias_1,bias_2])\n",
    "\n",
    "## Metrics definition\n",
    "correct_prediction = tf.equal(tf.argmax(y_train,1), tf.argmax(predicted_y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/20\n",
      "24421/24421 [==============================] - 1s 54us/sample - loss: 1.5216 - acc: 0.7889\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/20\n",
      "24421/24421 [==============================] - 1s 43us/sample - loss: 0.3816 - acc: 0.8079\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/20\n",
      "24421/24421 [==============================] - 1s 43us/sample - loss: 0.3723 - acc: 0.8135\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/20\n",
      "24421/24421 [==============================] - 1s 44us/sample - loss: 0.4528 - acc: 0.8138\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/20\n",
      "24421/24421 [==============================] - 1s 43us/sample - loss: 0.3701 - acc: 0.8173\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0044370530258241335.\n",
      "Epoch 6/20\n",
      "24421/24421 [==============================] - 1s 43us/sample - loss: 0.3619 - acc: 0.8193\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.004437053110450506.\n",
      "Epoch 7/20\n",
      "24421/24421 [==============================] - 1s 43us/sample - loss: 0.3579 - acc: 0.8187\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.004437053110450506.\n",
      "Epoch 8/20\n",
      "24421/24421 [==============================] - 1s 44us/sample - loss: 0.3573 - acc: 0.8205\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.004437053110450506.\n",
      "Epoch 9/20\n",
      "24421/24421 [==============================] - 1s 43us/sample - loss: 0.3569 - acc: 0.8202\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.004437053110450506.\n",
      "Epoch 10/20\n",
      "24421/24421 [==============================] - 1s 45us/sample - loss: 0.3559 - acc: 0.8232\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0008735421881480938.\n",
      "Epoch 11/20\n",
      "24421/24421 [==============================] - 1s 43us/sample - loss: 0.3505 - acc: 0.8224\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.0008735422161407769.\n",
      "Epoch 12/20\n",
      "24421/24421 [==============================] - 1s 43us/sample - loss: 0.3500 - acc: 0.8234\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0008735422161407769.\n",
      "Epoch 13/20\n",
      "24421/24421 [==============================] - 1s 42us/sample - loss: 0.3497 - acc: 0.8241\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0008735422161407769.\n",
      "Epoch 14/20\n",
      "24421/24421 [==============================] - 1s 43us/sample - loss: 0.3498 - acc: 0.8234\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0008735422161407769.\n",
      "Epoch 15/20\n",
      "24421/24421 [==============================] - 1s 42us/sample - loss: 0.3497 - acc: 0.8237\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 7.630759814295437e-05.\n",
      "Epoch 16/20\n",
      "24421/24421 [==============================] - 1s 43us/sample - loss: 0.3475 - acc: 0.8236\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 7.630759500898421e-05.\n",
      "Epoch 17/20\n",
      "24421/24421 [==============================] - 1s 42us/sample - loss: 0.3472 - acc: 0.8238\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 7.630759500898421e-05.\n",
      "Epoch 18/20\n",
      "24421/24421 [==============================] - 1s 42us/sample - loss: 0.3471 - acc: 0.8238\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 7.630759500898421e-05.\n",
      "Epoch 19/20\n",
      "24421/24421 [==============================] - 1s 41us/sample - loss: 0.3471 - acc: 0.8233\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 7.630759500898421e-05.\n",
      "Epoch 20/20\n",
      "24421/24421 [==============================] - 1s 41us/sample - loss: 0.3470 - acc: 0.8244\n",
      "24421/24421 - 1s - loss: 0.9903 - acc: 0.6327\n",
      "\n",
      "Test accuracy: 0.6326932\n"
     ]
    }
   ],
   "source": [
    "## mlp training\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# This is a sample of a scheduler I used in the past\n",
    "def lr_scheduler(epoch, lr):\n",
    "    decay_rate = 0.85\n",
    "    decay_step = 1\n",
    "    if epoch % 5 == 0 and epoch:\n",
    "        return lr * pow(decay_rate, np.floor(epoch / decay_step))\n",
    "    return lr\n",
    "\n",
    "callbacks = [LearningRateScheduler(lr_scheduler, verbose=1)]\n",
    "\n",
    "class_names = ['<50K', '>50K']\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(2)\n",
    "])\n",
    "optimizer = keras.optimizers.Adam(lr=0.01)\n",
    "epochs = 20\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train.astype(float), y_train.astype(float), callbacks=callbacks, epochs=epochs)\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 0]\n",
      "63.5\n"
     ]
    }
   ],
   "source": [
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "predictions = probability_model.predict(X_test)\n",
    "y_pred = []\n",
    "for i in predictions:\n",
    "    y_pred.append(np.argmax(i))\n",
    "print(y_pred[0:5])\n",
    "print(round(f1_score(y_test, y_pred, average='weighted') * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
